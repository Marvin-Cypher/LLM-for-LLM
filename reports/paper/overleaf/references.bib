% References for LLMs for LLMs: Legal Large Language Models Benchmark

% OpenAI Models
@misc{openai2025gpt5,
  author = {{OpenAI}},
  title = {{GPT-5}: Next Generation Language Model},
  year = {2025},
  url = {https://openai.com/gpt-5},
  note = {Accessed: 2025-01-01}
}

@misc{openai2024o3,
  author = {{OpenAI}},
  title = {O3-Mini: Reasoning-Optimized Language Model},
  year = {2024},
  url = {https://openai.com/o3-mini},
  note = {Accessed: 2024-12-01}
}

@misc{openai2024gpt4omini,
  author = {{OpenAI}},
  title = {{GPT-4o-mini}: Fast and Affordable Language Model},
  year = {2024},
  url = {https://openai.com/gpt-4o-mini},
  note = {Accessed: 2024-08-01}
}

@misc{openai2024batch,
  author = {{OpenAI}},
  title = {Batch {API}: Cost-Effective Async Processing},
  year = {2024},
  url = {https://platform.openai.com/docs/guides/batch},
  note = {Accessed: 2024-10-01}
}

% Anthropic Models
@misc{anthropic2025claude,
  author = {{Anthropic}},
  title = {Claude Sonnet 4.5: Constitutional {AI} for Safe and Helpful Responses},
  year = {2025},
  url = {https://www.anthropic.com/claude},
  note = {Accessed: 2025-01-01}
}

@article{bai2022constitutional,
  title={Constitutional {AI}: Harmlessness from {AI} Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

% Google Models
@misc{google2025gemini,
  author = {{Google DeepMind}},
  title = {Gemini 2.5 Flash: Fast Multi-Modal Language Model},
  year = {2025},
  url = {https://deepmind.google/technologies/gemini/},
  note = {Accessed: 2025-01-01}
}

% xAI Models
@misc{xai2024grok,
  author = {{xAI}},
  title = {Grok-4: Large Language Model Trained on {X} Data},
  year = {2024},
  url = {https://x.ai/grok},
  note = {Accessed: 2024-12-01}
}

% DeepSeek Models
@misc{deepseek2024v3,
  author = {{DeepSeek AI}},
  title = {DeepSeek-V3: Large-Scale Mixture-of-Experts Language Model},
  year = {2024},
  url = {https://www.deepseek.com/},
  note = {Accessed: 2024-12-01}
}

% Zhipu AI Models
@misc{zhipu2024glm,
  author = {{Zhipu AI}},
  title = {{GLM-4.6}: Bilingual Language Model for Chinese and English},
  year = {2024},
  url = {https://www.zhipuai.cn/},
  note = {Accessed: 2024-11-01}
}

% Mistral AI Models
@misc{mistral2024large,
  author = {{Mistral AI}},
  title = {Mistral Large: European Frontier Language Model},
  year = {2024},
  url = {https://mistral.ai/},
  note = {Accessed: 2024-10-01}
}

% Alibaba Models
@misc{alibaba2024qwen,
  author = {{Alibaba Cloud}},
  title = {Qwen 2.5 72{B}: Open-Weight Large Language Model},
  year = {2024},
  url = {https://qwenlm.github.io/},
  note = {Accessed: 2024-11-01}
}

% LLM-as-Judge and Evaluation
@inproceedings{zheng2024judging,
  title={Judging {LLM}-as-a-Judge with {MT}-Bench and Chatbot Arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{liu2023geval,
  title={G-Eval: {NLG} Evaluation using {GPT}-4 with Better Human Alignment},
  author={Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  journal={arXiv preprint arXiv:2303.16634},
  year={2023}
}

% Safety and Over-Refusal
@misc{falsereject2024,
  author = {Welbl, Johannes and Porada, Ian and Glaese, Amelia and Dathathri, Sumanth and Barnes, Charlie and Eisenschlos, Julian and Wang, Alex and Matejka, Justin and Uesato, Jonathan and Kumar, Shankar and Cotrescu, Bogdan and Singh, Siddharth and Bartolo, Max and Buchatskaya, Tatiana and Gribovskaya, Elena and van Krieken, Emile and Poulter, Sandy and Rauh, Maribeth and Hendricks, Lisa Anne and Gabriel, Iason},
  title = {{FalseReject}: A Dataset for Measuring Over-Refusal in Large Language Models},
  year = {2024},
  publisher = {HuggingFace and Amazon Science},
  url = {https://huggingface.co/datasets/HuggingFaceH4/FalseReject},
  note = {Accessed: 2024-11-01}
}

% Legal AI and Applications
@article{katz2024gpt4,
  title={{GPT-4} Passes the Bar Exam},
  author={Katz, Daniel Martin and Bommarito, Michael J and Gao, Shang and Arredondo, Pablo},
  journal={Philosophical Transactions of the Royal Society A},
  volume={382},
  number={2270},
  pages={20230254},
  year={2024}
}

@article{cui2023chatlaw,
  title={ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases},
  author={Cui, Jiaxi and Li, Zongjian and Yan, Yang and Chen, Baobao and Yuan, Li},
  journal={arXiv preprint arXiv:2306.16092},
  year={2023}
}

@inproceedings{chalkidis2022lexglue,
  title={{LexGLUE}: A Benchmark Dataset for Legal Language Understanding in English},
  author={Chalkidis, Ilias and Jana, Abhik and Hartung, Dirk and Bommarito, Michael and Androutsopoulos, Ion and Katz, Daniel Martin and Aletras, Nikolaos},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  pages={4310--4330},
  year={2022}
}

% Statistical Methods
@book{cohen1988statistical,
  title={Statistical Power Analysis for the Behavioral Sciences},
  author={Cohen, Jacob},
  year={1988},
  edition={2nd},
  publisher={Routledge}
}

% Infrastructure
@misc{openrouter2024,
  author = {{OpenRouter}},
  title = {{OpenRouter}: Unified {API} for Multiple {LLM} Providers},
  year = {2024},
  url = {https://openrouter.ai/},
  note = {Accessed: 2024-10-01}
}

% Benchmarking and Evaluation Frameworks
@inproceedings{liang2023holistic,
  title={Holistic Evaluation of Language Models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  booktitle={Transactions on Machine Learning Research},
  year={2023}
}

@article{hendrycks2021measuring,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}

% Contract Analysis
@article{manor2019plain,
  title={Plain English Summarization of Contracts},
  author={Manor, Laura and Li, Junyi Jessy},
  journal={arXiv preprint arXiv:1906.00424},
  year={2019}
}

@inproceedings{hendrycks2021cuad,
  title={{CUAD}: An Expert-Annotated {NLP} Dataset for Legal Contract Review},
  author={Hendrycks, Dan and Burns, Collin and Chen, Anya and Ball, Spencer},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2021}
}

% Responsible AI
@article{bender2021dangers,
  title={On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={610--623},
  year={2021}
}

@article{bommasani2021opportunities,
  title={On the Opportunities and Risks of Foundation Models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}
